{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Mailing - XGBoost Model - Calculado Correlacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desse notebook é demonstrar a utilizacao do XGBoost para a criacao de arvores de decisão para a predição de CUPS em mailings.\n",
    "\n",
    "Em primeiro lugar, definimos os imports que iremos usar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import gc\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import dateutil.parser as parser\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo definimos os diretorios e nomes dos arquivos intermediarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_location = \"../logs/\"\n",
    "arquivo_df_pickled_norm = \"../intermediate/df.norm.pickle\"\n",
    "arquivo_df_pickled_norm_corr = \"../intermediate/df.norm.corr.pickle\"\n",
    "arquivo_df_pickled_norm_train = \"../intermediate/df.norm.train.pickle\"\n",
    "arquivo_df_pickled_norm_test = \"../intermediate/df.norm.test.pickle\"\n",
    "arquivo_df_pickled_norm_train_x = \"../intermediate/df.norm.train.x.pickle.npy\"\n",
    "arquivo_df_pickled_norm_train_y = \"../intermediate/df.norm.train.y.pickle.npy\"\n",
    "arquivo_df_pickled_norm_test_x = \"../intermediate/df.norm.test.x.pickle.npy\"\n",
    "arquivo_df_pickled_norm_test_y = \"../intermediate/df.norm.test.y.pickle.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefinimos o logger que iremos usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'correlations.log.' + datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma função para imprimir tanto no log quanto no notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(msg):\n",
    "    logging.debug(msg)\n",
    "    print(msg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos para a memoria o arquivo normalizado e pickled que foi gerado no notebook de \"Preparação de Dados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Carregando Pickling normalizado:{}\".format(arquivo_df_pickled_norm))    \n",
    "chamadas = pd.read_pickle(arquivo_df_pickled_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos as dimensões do dataframe carregado.... E imprimimos uma amostra do dado que precisamos com apenas as colunas relevantes... Como podemos perceber o nosso modelo considera apenas colunas com valores booleanos (0 ou 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamadas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(chamadas.shape)\n",
    "chamadas.loc[:, 'NORM_CARTEIRA_W02':'NORM_LIGACOES'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratarmos as colunas de forma correta, precisamos eliminar os caracteres especiais das colunas, principalmente o espaco e o sinal de - para isso iremos rodar o codigo abaixo para tratar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = chamadas.columns\n",
    "cols = cols.map(lambda x: x.replace(' ', '_').replace('-','menos'))\n",
    "chamadas.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos q na realidade ter LIGACOES é fundamental para ter CUP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamadas_calculo_correlacao = chamadas.loc[:, 'NORM_CARTEIRA_W02':'NORM_CUP'].query('NORM_CUP >= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Registros com CUP:{}\".format(len(chamadas_calculo_correlacao)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamadas_calculo_correlacao_cup = chamadas_calculo_correlacao.loc[:, 'NORM_CUP':'NORM_CUP'].as_matrix().ravel().astype(float)\n",
    "print(chamadas_calculo_correlacao_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_campos_computados = { \"coluna\" : [], \"corr\": [] }\n",
    "\n",
    "for coluna in chamadas_calculo_correlacao.columns.values:\n",
    "    if coluna == 'NORM_CUP':\n",
    "        continue\n",
    "    chamadas_calculo_correlacao_coluna = chamadas_calculo_correlacao.loc[:, coluna:coluna].as_matrix().ravel().astype(float)\n",
    "    corr = abs(pearsonr(chamadas_calculo_correlacao_coluna, chamadas_calculo_correlacao_cup)[0] * 100)\n",
    "    corr_campos_computados['coluna'] = corr_campos_computados['coluna'] + [coluna]\n",
    "    corr_campos_computados['corr'] = corr_campos_computados['corr'] + [corr]\n",
    "\n",
    "corr = pd.DataFrame.from_dict(corr_campos_computados).sort_values('corr',ascending = False)\n",
    "corr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_finais = []\n",
    "for coluna in corr.coluna:\n",
    "    if coluna == 'NORM_TENTATIVAS':\n",
    "        continue\n",
    "    if coluna == 'NORM_LIGACOES':\n",
    "        continue        \n",
    "    if 'nan' in coluna:\n",
    "        continue\n",
    "    if 'DDD' in coluna:\n",
    "        break\n",
    "    colunas_finais = colunas_finais + [coluna]\n",
    "\n",
    "colunas_finais = colunas_finais + ['NORM_TENTATIVAS', 'NORM_LIGACOES', 'NORM_CUP']\n",
    "chamadas_novo = chamadas[colunas_finais]\n",
    "chamadas_novo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamadas_novo.to_pickle(arquivo_df_pickled_norm_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
