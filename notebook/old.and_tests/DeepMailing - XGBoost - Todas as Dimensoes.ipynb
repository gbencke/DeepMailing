{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Mailing - XGBoost Model - Todas as Dimensões e Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desse notebook é demonstrar a utilizacao do XGBoost para a criacao de arvores de decisão para a predição de CUPS em mailings.\n",
    "\n",
    "Em primeiro lugar, definimos os imports que iremos usar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import gc\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import dateutil.parser as parser\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaico definimos os diretorios e nomes dos arquivos intermediarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_location = \"../logs/\"\n",
    "arquivo_df_pickled_norm = \"../intermediate/df.norm.pickle\"\n",
    "arquivo_df_pickled_norm_train = \"../intermediate/df.norm.train.pickle\"\n",
    "arquivo_df_pickled_norm_test = \"../intermediate/df.norm.test.pickle\"\n",
    "arquivo_df_pickled_norm_train_x = \"../intermediate/df.norm.train.x.pickle.npy\"\n",
    "arquivo_df_pickled_norm_train_y = \"../intermediate/df.norm.train.y.pickle.npy\"\n",
    "arquivo_df_pickled_norm_test_x = \"../intermediate/df.norm.test.x.pickle.npy\"\n",
    "arquivo_df_pickled_norm_test_y = \"../intermediate/df.norm.test.y.pickle.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefinimos o logger que iremos usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'xgboost.log.' + datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma função para imprimir tanto no log quanto no notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(msg):\n",
    "    logging.debug(msg)\n",
    "    print(msg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos para a memoria o arquivo normalizado e pickled que foi gerado no notebook de \"Preparação de Dados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Carregando Pickling normalizado:{}\".format(arquivo_df_pickled_norm))    \n",
    "chamadas = pd.read_pickle(arquivo_df_pickled_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos as dimensões do dataframe carregado.... E imprimimos uma amostra do dado que precisamos com apenas as colunas relevantes... Como podemos perceber o nosso modelo considera apenas colunas com valores booleanos (0 ou 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(chamadas.shape)\n",
    "chamadas.loc[:, 'NORM_CARTEIRA_A01':'NORM_DDD_87'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfeito, então vamos embaralhar os dados e gerar os nossos dados de treinamento e teste. Vamos considerar 70% para treinamento e 30 % para teste. No final, apagamos o dataframe lido para economizar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Criando Pickling de train e teste...\")\n",
    "chamadas = chamadas.sample(int(len(chamadas.index)))\n",
    "chamadas_train = chamadas.tail(int(len(chamadas.index) * 0.7))\n",
    "chamadas_test = chamadas.head(int(len(chamadas.index) * 0.3))\n",
    "del chamadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma função para gerar um arquivo de referencia de colunas a serem usadas q que vai ser importante na hora de gerar a arvore de decisao..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_reference(header_chamadas_x,arquivo_df_pickled_norm_train_x):\n",
    "    print_log(\"Criando Arquivo de referencia de colunas...\")\n",
    "    with open(arquivo_df_pickled_norm_train_x+\".txt\",\"w\") as f:\n",
    "        counter = 0\n",
    "        lista_header = list(header_chamadas_x.columns.values)\n",
    "        for header in lista_header:\n",
    "            f.write(\"{}-{}\\n\".format(counter,header))\n",
    "            counter=counter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos agora os nossos dataframes de X que são as features e as Y que são os alvos de predição. Também removemos qualquer linha em tentativas seja igual a zero, além de criar um arquivo de referencia com as colunas X que serão usadas no modelo. Esses dataframes serão convertidos para matrizes no formato numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Separando colunas em X e Y...\")        \n",
    "chamadas_train = chamadas_train[(chamadas_train.NORM_TENTATIVAS > 0)]\n",
    "create_column_reference(chamadas_train.loc[:, chamadas_train.columns.values[2]:'NORM_DDD_87'].head(1), arquivo_df_pickled_norm_train_x)\n",
    "chamadas_train_x = chamadas_train.loc[:, chamadas_train.columns.values[2]:'NORM_DDD_87'].as_matrix()\n",
    "chamadas_train_y = chamadas_train.NORM_CUP.as_matrix()\n",
    "chamadas_test = chamadas_test[(chamadas_test.NORM_TENTATIVAS > 0)]\n",
    "chamadas_test_x = chamadas_test.loc[:, chamadas_test.columns.values[2]:'NORM_DDD_87'].as_matrix()\n",
    "chamadas_test_y = chamadas_test.NORM_CUP.as_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a criação das matrizes numpy, gravamos elas em arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Criando arquivos finais em formato NUMPY para consumo pelo algoritmo...\")        \n",
    "np.save(arquivo_df_pickled_norm_train_x,chamadas_train_x)\n",
    "np.save(arquivo_df_pickled_norm_train_y,chamadas_train_y)\n",
    "np.save(arquivo_df_pickled_norm_test_x,chamadas_test_x)\n",
    "np.save(arquivo_df_pickled_norm_test_y,chamadas_test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apagamos todos os dados intermediários e rodamos o garbage collector para economizar memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Removendo objetos desnecessarios\")        \n",
    "del chamadas_train_x\n",
    "del chamadas_train_y\n",
    "del chamadas_train\n",
    "del chamadas_test\n",
    "del chamadas_test_x\n",
    "del chamadas_test_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos os objetos numpy em memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Carregando objetos numpy\")        \n",
    "train_x = np.load(arquivo_df_pickled_norm_train_x)\n",
    "train_y = np.load(arquivo_df_pickled_norm_train_y)\n",
    "test_x = np.load(arquivo_df_pickled_norm_test_x)\n",
    "test_y = np.load(arquivo_df_pickled_norm_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contamos quantos CUPS existem em treinamento e teste..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = \"Train - CUPS Detectados {} num universo de {}\".format(len([y for y in train_y if y >0]),len(train_y))\n",
    "msg2 = \"Test - CUPS Detectados {} num universo de {}\".format(len([y for y in test_y if y >0]),len(test_y))\n",
    "print_log(msg1)\n",
    "print_log(msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos os parametros para o XGBoost, especificando que queremos que ele seja o mais exato possivel, que a medida de erro é erro simples e que queremos apenas uma classificacao binaria com um maximo de 1000 interações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['eta'] = 0.2\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'error'\n",
    "param['tree_method'] = 'exact'\n",
    "param['silent'] = 0\n",
    "num_round = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a definicão dos paramêtros de teste, criamos as matrizes no formato do XGBoost e treinamos o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "print_log(\"Starting model for params:{}\".format(param))\n",
    "dtrain = xgb.DMatrix(train_x, train_y)\n",
    "dtest = xgb.DMatrix(test_x, test_y)\n",
    "gpu_res = {}\n",
    "booster = xgb.train(param, dtrain, num_round, evals=[], evals_result=gpu_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o modelo ser treinado, podemos plotar ele... Para verificar que coluna é cada feature no modelo, por favor ver a lista em anexo no final desse notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 80,50\n",
    "plot_tree(booster, rankdir='LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos tentar predizer os dados com o nosso modelo treinado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = booster.predict(dtest)\n",
    "test_predictions = np.array([value for value in test_y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E Finalmente medir a precisão da nossa predição... Tanto no total quanto em CUPs detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_y, test_predictions.round())\n",
    "print_log(\"CUPS Previstos:{}\".format(len([x for x in test_predictions if x > 0.5])))\n",
    "print_log(\"CUPS na Base Teste:{}\".format(len([x for x in test_y if x > 0.5])))\n",
    "print_log(\"Accuracy Total:{}\".format(accuracy))\n",
    "print_log(\"Accuracy em CUPs:{}\".format(len([x for x in test_predictions if x > 0.5]) / len([x for x in test_y if x > 0.5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após, vamos salvar o modelo gerado em um arquivo para reuso..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"../output/{}.model\".format(datetime.now().strftime(\"%Y%m%d.%H%M%S\"))\n",
    "with open(save_file, 'wb') as fp:\n",
    "    pickle.dump(booster, fp)    \n",
    "print_log(\"Model saved as {}\".format(save_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "cat ../intermediate/df.norm.train.x.pickle.npy.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
