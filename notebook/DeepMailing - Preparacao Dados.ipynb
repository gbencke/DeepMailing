{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Mailing - Preparação de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil.parser as parser\n",
    "import os.path\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "\n",
    "log_location = \"../logs/\"\n",
    "arquivo_chamadas = \"../data/mailing_completo.txt.full\"\n",
    "arquivo_df_pickled = \"../intermediate/df.pickle\"\n",
    "arquivo_df_pickled_norm = \"../intermediate/df.norm.pickle\"\n",
    "arquivo_df_pickled_norm_train = \"../intermediate/df.norm.train.pickle\"\n",
    "arquivo_df_pickled_norm_test = \"../intermediate/df.norm.test.pickle\"\n",
    "\n",
    "arquivo_df_pickled_norm_train_x = \"../intermediate/df.norm.train.x.pickle\"\n",
    "arquivo_df_pickled_norm_train_y = \"../intermediate/df.norm.train.y.pickle\"\n",
    "arquivo_df_pickled_norm_test_x = \"../intermediate/df.norm.test.x.pickle\"\n",
    "arquivo_df_pickled_norm_test_y = \"../intermediate/df.norm.test.y.pickle\"\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "num_partitions = 8\n",
    "num_cores = 8\n",
    "Normalizado = False\n",
    "\n",
    "\n",
    "#Delete Jupyter notebook root logger handler\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'prepare_data.log.' + \\\n",
    "                                          datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Declarando as funcoes globais\")\n",
    "\n",
    "def IsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def IsIntAndGreaterZero(s):\n",
    "    return IsInt(s) and int(s)>0\n",
    "    \n",
    "def IsFloat(s):\n",
    "    try: \n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def IsDatetime(s):\n",
    "    try: \n",
    "        parser.parse(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def ConverterInt(val):\n",
    "    val = val.replace(\",\",\".\")\n",
    "    if IsInt(val):\n",
    "        return int(val)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ConverterFloat(val):\n",
    "    val = val.replace(\",\",\".\")\n",
    "    if IsFloat(val):\n",
    "        return float(val)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def ConverterData(val):\n",
    "    if IsDatetime(val):\n",
    "        return parser.parse(val)\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "def func_str(x):\n",
    "    return str(x)\n",
    "\n",
    "def func_strip(x):\n",
    "    return str(x).strip()\n",
    "\n",
    "def func_start_ALTA(x):\n",
    "    return str(x).startswith('ALTA')\n",
    "\n",
    "def IsCSVDataAvailable():\n",
    "    return os.path.isfile(arquivo_df_pickled)\n",
    "\n",
    "def IsNormDataAvailable():\n",
    "    return os.path.isfile(arquivo_df_pickled_norm)\n",
    "\n",
    "def IsTrainDataAvailable():\n",
    "    return os.path.isfile(arquivo_df_pickled_norm_train)\n",
    "    \n",
    "def IsNumpyArrayDataAvailable():\n",
    "    return os.path.isfile(arquivo_df_pickled_norm_train_x + \".npy\")\n",
    "\n",
    "def limpar_df(chamadas):\n",
    "    del chamadas[\"CPF_CNPJ\"]\n",
    "    del chamadas[\"PRODUTO\"]\n",
    "    del chamadas[\"FILA\"]\n",
    "    del chamadas[\"STATUS_CONTRATO\"]\n",
    "    del chamadas[\"DETALHE_ORIGEM\"]\n",
    "    del chamadas[\"TELEFONE\"]\n",
    "    del chamadas[\"TELRUIM_RENITENCIA\"]\n",
    "    del chamadas[\"TELRUIM_DISCADOR\"]\n",
    "    del chamadas[\"OPERADORA\"]\n",
    "    del chamadas[\"ORIGEM_ULTIMA_ATUALIZACAO\"]\n",
    "    del chamadas[\"PRIMEIRA_ORIGEM\"]\n",
    "    del chamadas[\"ATRASO\"] \n",
    "    del chamadas[\"VALOR\"]\n",
    "    del chamadas[\"DT_ENTRADA\" ]\n",
    "    del chamadas[\"NLOC\"]\n",
    "    del chamadas[\"SCORE_C\"]\n",
    "    del chamadas[\"SCORE_E\"]\n",
    "    del chamadas[\"RENDA\"]\n",
    "    del chamadas[\"DT_DEVOLUCAO\"]\n",
    "    del chamadas[\"VLRISCO\"]\n",
    "    del chamadas[\"SCORE_ZANC_C\"]\n",
    "    del chamadas[\"SCORE_ZANC_E\"]\n",
    "    del chamadas[\"SCORE_ZANC\"]\n",
    "    del chamadas[\"DATA_PRIMEIRA_ORIGEM\"]\n",
    "    del chamadas[\"DATA_ULTIMA_ATUALIZACAO\"]\n",
    "    del chamadas[\"ULT_ARQ_BUREAU\"]\n",
    "  \n",
    "    return chamadas\n",
    "\n",
    "def parallelize_dataframe(func, data):\n",
    "    df = data['df']\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    items = list(data.items())\n",
    "    chunksize = len(data.items())\n",
    "    chunks = [items[i:i + chunksize ] for i in range(0, len(items), chunksize)]\n",
    "    df = pd.concat(pool.map(func, chunks))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "\n",
    "def func_to_execute_column_str(data):\n",
    "    data = dict(item for item in data)  # Convert back to a dict\n",
    "    logging.debug(\"Creating Binary Column:{} in {}\".format(data[\"col\"],  data[\"source_col\"]))\n",
    "    df = data['df']\n",
    "    df['NORM_' + data[\"source_col\"] + \"_\" + data[\"col\"]] = df.apply(lambda row: 1 if func_str(row[data[\"source_col\"]]) == data[\"col\"] else 0, axis=1)\n",
    "    return df\n",
    "    \n",
    "def CreateColumnStr(cols, df, source_col):\n",
    "    for col in cols:\n",
    "        df = parallelize_dataframe(func_to_execute_column_str, { \"df\" : df, \"source_col\" : source_col, \"col\" : col})\n",
    "    return df    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def func_to_execute_column_strip(data):\n",
    "    data = dict(item for item in data)  # Convert back to a dict\n",
    "    logging.debug(\"Creating Binary Column:{} in {}\".format(data[\"col\"],  data[\"source_col\"]))\n",
    "    df = data['df']\n",
    "    df['NORM_' + data[\"source_col\"] + \"_\" + data[\"col\"]] = df.apply(lambda row: 1 if func_strip(row[data[\"source_col\"]]) == data[\"col\"] else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def CreateColumnStrip(cols, df, source_col):\n",
    "    for col in cols:\n",
    "        df = parallelize_dataframe(func_to_execute_column_strip, { \"df\" : df, \"source_col\" : source_col, \"col\" : col})\n",
    "    return df    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def func_to_execute_column_ALTA(data):\n",
    "    data = dict(item for item in data)  # Convert back to a dict\n",
    "    logging.debug(\"Creating Binary Column:{} in {}\".format(data[\"col\"],  data[\"source_col\"]))\n",
    "    df = data['df']\n",
    "    df['NORM_' + data[\"source_col\"] + \"_\" + data[\"col\"]] = df.apply(lambda row: 1 if func_start_ALTA(row[data[\"source_col\"]]) == data[\"col\"] else 0, axis=1)\n",
    "    return df\n",
    "    \n",
    "def CreateColumnALTA(cols, df, source_col):\n",
    "    for col in cols:\n",
    "        df = parallelize_dataframe(func_to_execute_column_ALTA, { \"df\" : df, \"source_col\" : source_col, \"col\" : col})\n",
    "    return df    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def func_to_execute_numeric(data):\n",
    "    data = dict(item for item in data)  # Convert back to a dict\n",
    "    logging.debug(\"Creating Numeric Column:{} \".format(data[\"source_col\"]))\n",
    "    df = data['df']\n",
    "    df['NORM_' + data[\"source_col\"]] = df.apply(lambda row: 1 if IsIntAndGreaterZero(row[data[\"source_col\"]]) else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def CreateLogColumn(df, source_col):\n",
    "    df = parallelize_dataframe(func_to_execute_numeric, { \"df\" : df, \"source_col\" : source_col})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Declarando os tipos de dados no dataframe\")\n",
    "\n",
    "df_dtypes = {\n",
    "    \"CPF_CNPJ\": \"object\",\n",
    "    \"CARTEIRA\": \"object\",\n",
    "    \"SEGMENTO\": \"object\",\n",
    "    \"PRODUTO\": \"object\",\n",
    "    \"FILA\": \"object\",\n",
    "    \"STATUS_CONTRATO\": \"object\",\n",
    "    \"PROPENSAO\": \"object\",\n",
    "    \"ORIGEM\": \"object\",\n",
    "    \"DETALHE_ORIGEM\": \"object\",\n",
    "    \"STATUS_BUREAU\": \"object\",\n",
    "    \"STATUS_INTERNA\": \"object\",\n",
    "    \"DDD\": \"object\",\n",
    "    \"TELEFONE\": \"object\",\n",
    "    \"TELRUIM_RENITENCIA\": \"object\",\n",
    "    \"TELRUIM_DISCADOR\": \"object\",\n",
    "    \"STATUS_TELEFONE\": \"object\",\n",
    "    \"OPERADORA\": \"object\",\n",
    "    \"ORIGEM_ULTIMA_ATUALIZACAO\": \"object\",\n",
    "    \"PRIMEIRA_ORIGEM\": \"object\"\n",
    "}\n",
    "\n",
    "converters = {\n",
    "    \"ATRASO\":  ConverterInt,\n",
    "    \"VALOR\": ConverterFloat,\n",
    "    \"DT_ENTRADA\" : ConverterData,\n",
    "    \"NLOC\": ConverterInt,\n",
    "    \"SCORE_C\": ConverterInt,\n",
    "    \"SCORE_E\": ConverterInt,\n",
    "    \"RENDA\": ConverterFloat,\n",
    "    \"DT_DEVOLUCAO\": ConverterData,\n",
    "    \"VLRISCO\": ConverterFloat,\n",
    "    \"SCORE_ZANC_C\": ConverterInt,\n",
    "    \"SCORE_ZANC_E\": ConverterInt,\n",
    "    \"SCORE_ZANC\": ConverterInt,\n",
    "    \"DATA_PRIMEIRA_ORIGEM\": ConverterData,\n",
    "    \"DATA_ULTIMA_ATUALIZACAO\": ConverterData,\n",
    "    \"TENTATIVAS\": ConverterInt,\n",
    "    \"ULT_ARQ_BUREAU\": ConverterData,\n",
    "    \"DATA_MAILING\": ConverterData,\n",
    "    \"LIGACOES\": ConverterInt,\n",
    "    \"CUP\": ConverterInt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Carregando dos dados em CSV ou normalizados, dependendo da existencia deles...\")\n",
    "if not IsCSVDataAvailable():\n",
    "    chamadas = pd.read_csv(arquivo_chamadas, sep=\"|\", dtype=df_dtypes, converters = converters)\n",
    "    chamadas = limpar_df(chamadas)\n",
    "    chamadas.to_pickle(arquivo_df_pickled)\n",
    "else:\n",
    "    if not IsNormDataAvailable():    \n",
    "        chamadas = pd.read_pickle(arquivo_df_pickled)\n",
    "    else:\n",
    "        chamadas = pd.read_pickle(arquivo_df_pickled_norm)\n",
    "        Normalizado = True\n",
    "        \n",
    "logging.debug(\"Normalizado:{}\".format(Normalizado))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Calculando Datas minimas e maximas...\")\n",
    "data_maxima_mailing = chamadas.DATA_MAILING.max()\n",
    "data_minima_mailing = chamadas.DATA_MAILING.min()\n",
    "\n",
    "print(\"Max:{} Min:{}\".format(data_maxima_mailing, data_minima_mailing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando Carteiras...\")\n",
    "if not Normalizado:\n",
    "    Carteiras = set([x for x in chamadas.CARTEIRA.unique()[:-1] if len(x) == 3])\n",
    "    chamadas = CreateColumnStr(Carteiras,chamadas, 'CARTEIRA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando Segmentos...\")\n",
    "if not Normalizado:\n",
    "    Segmentos = set([x.strip() for x in chamadas.SEGMENTO.unique()[:-1] if len(x.strip()) == 2])\n",
    "    chamadas = CreateColumnStrip(Segmentos,chamadas, 'SEGMENTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando Chamadas...\")\n",
    "if not Normalizado:\n",
    "    Propensao = set([x[:4] for x in chamadas.PROPENSAO.unique() if str(x).startswith(\"ALTA\")])\n",
    "    chamadas = CreateColumnALTA(Propensao,chamadas, 'PROPENSAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando Origem...\")\n",
    "if not Normalizado:\n",
    "    Origem = set([x for x in chamadas.ORIGEM.unique()[:-1]])\n",
    "    chamadas = CreateColumnStr(Origem,chamadas, 'ORIGEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando StatusBureau...\")\n",
    "if not Normalizado:\n",
    "    StatusBureau = set([str(x) for x in chamadas.STATUS_BUREAU.unique()])\n",
    "    chamadas = CreateColumnStr(StatusBureau,chamadas, 'STATUS_BUREAU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando StatusInterna...\")\n",
    "if not Normalizado:\n",
    "    StatusInterna = set([str(x) for x in chamadas.STATUS_INTERNA.unique()[:-1]])\n",
    "    chamadas = CreateColumnStr(StatusInterna,chamadas, 'STATUS_INTERNA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando Telefone...\")\n",
    "if not Normalizado:\n",
    "    StatusTelefone = set([str(x) for x in chamadas.STATUS_TELEFONE.unique()[:-1]])\n",
    "    chamadas = CreateColumnStr(StatusTelefone,chamadas, 'STATUS_TELEFONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando DDD...\")\n",
    "if not Normalizado:\n",
    "    DDD = set([str(x) for x in chamadas.DDD.unique()[:-1]])\n",
    "    chamadas = CreateColumnStr(DDD,chamadas, 'DDD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Normalizando LIGACOES E TAL...\")\n",
    "if not Normalizado:\n",
    "    chamadas = CreateLogColumn(chamadas,'TENTATIVAS')\n",
    "    chamadas = CreateLogColumn(chamadas,'LIGACOES')\n",
    "    chamadas = CreateLogColumn(chamadas,'CUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Removendo Campos desnecessarios e pickling...\")\n",
    "if not Normalizado:\n",
    "    del chamadas['NUMERO']\n",
    "    del chamadas['TENTATIVAS']\n",
    "    del chamadas['LIGACOES']\n",
    "    del chamadas['CUP']\n",
    "    del chamadas['DDD']\n",
    "    del chamadas['STATUS_TELEFONE']\n",
    "    del chamadas['STATUS_INTERNA']\n",
    "    del chamadas['STATUS_BUREAU']\n",
    "    del chamadas['ORIGEM']\n",
    "    del chamadas['SEGMENTO']\n",
    "    del chamadas['PROPENSAO']\n",
    "    del chamadas['CARTEIRA']\n",
    "    chamadas.to_pickle(arquivo_df_pickled_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
